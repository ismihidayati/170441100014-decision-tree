



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Menjelaskan tentang decision tree(pohon keputusan)">
      
      
        <link rel="canonical" href="https://ismihidayati.github.io/170441100014-decision-tree/New folder/">
      
      
        <meta name="author" content="Ismi Nur Hidayati.Z">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Materi Data Mining</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#k-means-clustering" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://ismihidayati.github.io/170441100014-decision-tree" title="Materi Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Materi Data Mining
            </span>
            <span class="md-header-nav__topic">
              Home
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://ismihidayati.com/170441100014-decision-tree" title="Go to repository" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    ismihidayati/170441100014-decision-tree
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Materi" class="md-tabs__link md-tabs__link--active">
        Materi
      </a>
    
  </li>

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://ismihidayati.github.io/170441100014-decision-tree" title="Materi Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Materi Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://ismihidayati.com/170441100014-decision-tree" title="Go to repository" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    ismihidayati/170441100014-decision-tree
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Materi" class="md-nav__link">
      Materi
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" title="K-Means Clustering" class="md-nav__link">
    K-Means Clustering
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-definisi-k-means-clustering" title="1. Definisi K-Means Clustering" class="md-nav__link">
    1. Definisi K-Means Clustering
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-beberapa-permasalahan-yang-terkait-dengan-k-means-clustering" title="2. Beberapa Permasalahan yang Terkait Dengan K-Means Clustering" class="md-nav__link">
    2. Beberapa Permasalahan yang Terkait Dengan K-Means Clustering
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-karakteristik-k-means" title="3. Karakteristik K-Means" class="md-nav__link">
    3. Karakteristik K-Means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-kelebihan-k-means" title="4. Kelebihan k-means" class="md-nav__link">
    4. Kelebihan k-means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-kekurangan-dari-k-means" title="5. Kekurangan dari k-means:" class="md-nav__link">
    5. Kekurangan dari k-means:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-penerapan-k-means-clustering" title="6. Penerapan K-Means Clustering" class="md-nav__link">
    6. Penerapan K-Means Clustering
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Home</h1>
                
                <h2 id="k-means-clustering"><strong>K-Means Clustering</strong><a class="headerlink" href="#k-means-clustering" title="Permanent link">&para;</a></h2>
<h3 id="1-definisi-k-means-clustering">1. Definisi K-Means Clustering<a class="headerlink" href="#1-definisi-k-means-clustering" title="Permanent link">&para;</a></h3>
<p><strong>K-Means Clustering</strong> adalah suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang
melakukan pengelompokan data dengan sistem partisi.</p>
<p>Terdapat dua jenis data clustering yang sering dipergunakan
dalam proses pengelompokan data yaitu  :</p>
<p><strong>Hierarchical</strong> dan <strong>Non-Hierarchical</strong>, dan <strong>K-Means</strong> merupakan salah satu metode data
clustering non-hierarchical atau <strong>Partitional
Clustering</strong>.</p>
<p><img alt="1557584977163" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557584977163.png" /></p>
<p>Metode <strong>K-Means Clustering</strong> berusaha mengelompokkan
data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok
mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik
yang berbeda dengan data yang ada di dalam kelompok yang lain.</p>
<p><img alt="1557585026246" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557585026246.png" /></p>
<p>Dengan kata lain, metode <strong>K-Means Clustering</strong> bertujuan untuk meminimalisasikan <strong>objective
function</strong> yang diset dalam proses clustering dengan cara <strong>meminimalkan variasi antar data
yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada
di cluster lainnya</strong>.</p>
<p><img alt="1557585088086" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557585088086.png" /></p>
<p>Data clustering menggunakan metode <strong>K-Means Clustering</strong> ini secara umum dilakukan dengan algoritma dasar sebagai berikut:</p>
<p>\1.   Tentukan jumlah cluster</p>
<p>\2.   Alokasikan data ke dalam cluster secara random</p>
<p>\3.   Hitung centroid/rata-rata dari data yang ada di masing-masing cluster</p>
<p>\4.   Alokasikan masing-masing data ke centroid/rata-rata terdekat</p>
<p>\5.   Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai centroid, ada yang di atas nilai threshold yang ditentukan atau apabila perubahan nilai pada objective function yang digunakan di atas nilai threshold yang ditentukan.</p>
<p><img alt="1557585175784" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557585175784.png" /></p>
<h3 id="2-beberapa-permasalahan-yang-terkait-dengan-k-means-clustering"><strong>2. Beberapa Permasalahan yang Terkait Dengan K-Means Clustering</strong><a class="headerlink" href="#2-beberapa-permasalahan-yang-terkait-dengan-k-means-clustering" title="Permanent link">&para;</a></h3>
<p>Beberapa permasalahan yang sering muncul pada saat menggunakan metode K-Means untuk melakukan pengelompokan data adalah:</p>
<p>\1.   Ditemukannya beberapa model clustering yang berbeda</p>
<p>\2.   Pemilihan jumlah cluster yang paling tepat</p>
<p>\3.   Kegagalan untuk converge</p>
<p>\4.   Outliers</p>
<p>\5.   Bentuk cluster</p>
<p>\6.   Overlapping</p>
<p>Keenam permasalahan ini adalah beberapa hal yang perlu diperhatikan pada saat menggunakan K-Means dalam mengelompokkan data.</p>
<h3 id="3-karakteristik-k-means"><strong>3. Karakteristik K-Means</strong><a class="headerlink" href="#3-karakteristik-k-means" title="Permanent link">&para;</a></h3>
<p>\1.   K-Means sangat cepat dalam proses clustering</p>
<p>\2.   K-Means sangat sensitif pada pembangkitan centroid awal secara random</p>
<p>\3.   Memungkinkan suatu cluster tidak mempunyai anggota</p>
<p>\4.   Hasil clustering dengan K-Means bersifat tidak unik (selalu berubah-ubah) – terkadang baik, terkadang jelek</p>
<p>\5.   K-means sangat sulit untuk mencapai global optimum</p>
<h3 id="4-kelebihan-k-means"><strong>4. Kelebihan k-means</strong><a class="headerlink" href="#4-kelebihan-k-means" title="Permanent link">&para;</a></h3>
<p>\1.    Mudah dilakukan saat pengimpelementasian dan di jalankan.</p>
<p>\2.    Waktu yang di butuhkan untuk melakukan pembelajaran relatif lebih cepat.</p>
<p>\3.    Sangat fleksibel, adaptasi yang mudah untuk di lakukan</p>
<p>\4.    Sangat umum penggunaannya.</p>
<p>\5.    Menggunakan prinsip yang sederhana dapat di jelaskan dalam non-statistik.</p>
<h3 id="5-kekurangan-dari-k-means"><strong>5. Kekurangan dari k-means:</strong><a class="headerlink" href="#5-kekurangan-dari-k-means" title="Permanent link">&para;</a></h3>
<p>\1.    Sebelum algoritma di jalankan, titik K diinisialisasikan secara random sehingga pengelompokan data yang di dapatkan bisa berbeda-beda. Namun apabila nilai yang diperoleh acak untuk penginisialisasi kurang baik maka pengelompokan yang didapatkn menjadi tidak optimal.</p>
<p>\2.    Apabila terjebak dalam kasus yang biasanya di sebut dengan curse of dimensionality. Hal ini pun akan terjadi apabila salah satu data untuk melakukan pelatihan mempunyai dimensi yang sangat banyak, sebagai contoh; jika ada data pelatihan yang terdiri dari 2 buah atribut saja maka dimensinya ada 2 dimensi pula, namun akan berbeda jika ada 20 atribut maka akan ada 20 dimensi yang di miliki. Adapun salah satu dari cara kerja algoritma cluster ini ialah untuk mencari jarak terdekat dari antara k titik dangan titik lainnya. Apabila ingin mencari jarak untuk antar titik dari 2 dimensi hal itu masih mudah untuk di lakukan, namun bagaimana dengan 20 buah dimensi hal tersebut akan menjadi lebih sulit untuk di lakukan pencarian jarak.</p>
<p>\3.    Apabila hanya ada terdapat beberapa buah titik sampel data yang ada, maka hal yang mudah untuk melakukan penghitungan dan mencari jarak titik terdekat dengan k titik yang telah di lakukan inisialisasi yang secara acak. Namun jika ada banyak titik data, misalkan satu juta data, maka perhitungan dan pencarian titik terdekat akan sangat membutuhkan waktu yang lama. Proses tersebut dapat dipercepat namun dibutuhkan sebuah struktur data yang lebih rumit seperti kD-tree atau hashing untuk melakukan proses tersebut.</p>
<p>\4.    Adanya penggunaan k buah random, tidak ada jaminan untuk menemukan kumpulan cluster yang optimal.</p>
<h3 id="6-penerapan-k-means-clustering"><strong>6. Penerapan K-Means Clustering</strong><a class="headerlink" href="#6-penerapan-k-means-clustering" title="Permanent link">&para;</a></h3>
<p><strong>Bahan yang dibutuhkan untuk pembuatan K-Means Clustering :</strong></p>
<ol>
<li>
<p>Data dengan format csv . misalnya saya disini membuat data penanaman pohon</p>
</li>
<li>
<p>Install Python.</p>
</li>
<li>
<p>Install pandas di cmd untuk membaca data dengan format csv .</p>
</li>
</ol>
<pre class="codehilite"><code class="language-python">pip install pandas </code></pre>

<ol>
<li>Install Numpy di cmd .  Numpy merupakan salah satu <em>library</em> yang digunakan oleh <em>library</em> lain seperti Scikit-Learn untuk keperluan analisis data.</li>
</ol>
<pre class="codehilite"><code class="language-python">pip install matplotlib</code></pre>

<ol>
<li>Lalu ketikkan script berikut pada python </li>
</ol>
<pre class="codehilite"><code class="language-python">#mengimport library

import csv
import math
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
akar = math.sqrt

#mengimport datatest

def program():
    dataset = pd.read_csv("data penanaman pohon.csv")

    # mengambil kolom 3 dan 5
    kol_mandiri = dataset.iloc[:, 1].values
    kol_jumlah = dataset.iloc[:, 2].values

    def mencari_centroid_dst():
        # mengambil letak centroid pertama acak
        random1 = []
        for i in range(30):
            random1.append(i)
        hasil_random1 = random.choice(random1)

        # hasil centroid pertama acak
        cen_pertama1 = kol_mandiri[hasil_random1]
        cen_pertama2 = kol_jumlah[hasil_random1]

        # mengambil letak centroid kedua acak
        random2 = []
        for j in range(30):
            random2.append(j)
        hasil_random2 = random.choice(random2)

        # hasil centroid kedua acak
        cen_kedua1 = kol_mandiri[hasil_random2]
        cen_kedua2 = kol_jumlah[hasil_random2]

        if (cen_pertama1==cen_kedua1 and cen_pertama2==cen_kedua2):
            mencari_centroid_dst()
        else:

            # menghitung distance ke centroid 1 dan centroid 2
            hasil_hitung_pertama1 = []
            hasil_hitung_pertama2 = []
            hasil1 = []
            hasil2 = []
            anggota1_kiri = []
            anggota1_kanan = []
            anggota2_kanan = []
            anggota2_kiri = []
            jml_awal1 = []
            jml_awal2 = []

            for a in range(len(kol_mandiri)):
                for b in range(len(kol_jumlah)):
                    if (a==b):
                        jarak1 = akar(((cen_pertama1 - kol_mandiri[a])**2) + ((cen_pertama2 - kol_jumlah[a])**2))
                        jarak2 = akar(((cen_kedua1 - kol_mandiri[a])**2) + ((cen_kedua2 - kol_jumlah[a])**2))
                        if(jarak1 &lt; jarak2):
                            hasil1.append(jarak1)
                            anggota1_kiri.append(kol_mandiri[a])
                            anggota1_kanan.append(kol_jumlah[a])
                            hasil_hitung_pertama1.append(jarak1)
                            jml_awal1.append(jarak1)
                            hasil_hitung_pertama2.append(jarak2)
                        else:
                            hasil2.append(jarak2)
                            anggota2_kanan.append(kol_jumlah[a])
                            anggota2_kiri.append(kol_mandiri[a])
                            hasil_hitung_pertama2.append(jarak2)
                            jml_awal2.append(jarak2)
                            hasil_hitung_pertama1.append(jarak1)

            # menghitung rata-rata tiap kolom sebagai pusat cluster yang baru

            hasil1_baru = []
            hasil2_baru = []
            anggota_clus1 = []
            anggota_clus2 = []
            seluruh_kiri = []
            seluruh_kanan = []
            anggota1_kiribaru = []
            anggota1_kananbaru = []
            anggota2_kiribaru = []
            anggota2_kananbaru = []

            rata1_a = sum(anggota1_kiri) / len(anggota1_kiri)
            rata1_b = sum(anggota1_kanan) / len(anggota1_kanan)
            rata2_a = sum(anggota2_kiri) / len(anggota2_kiri)
            rata2_b = sum(anggota2_kanan) / len(anggota2_kanan)

            for j in range(len(kol_mandiri)):
                for k in range(len(kol_jumlah)):
                    if(j==k):
                        dist1 = akar(((rata1_a - kol_mandiri[j])**2) + ((rata1_b - kol_jumlah[j])**2))
                        dist2 = akar(((rata2_a - kol_mandiri[j])**2) + ((rata2_b - kol_jumlah[j])**2))
                        if (dist1&lt;dist2):
                            hasil1_baru.append(dist1)
                            seluruh_kiri.append(dist1)
                            seluruh_kanan.append(dist2)
                            anggota_clus1.append(kol_mandiri[j])
                            anggota1_kiribaru.append(kol_mandiri[j])
                            anggota1_kananbaru.append(kol_jumlah[j])
                        else:
                            hasil2_baru.append(dist2)
                            seluruh_kanan.append(dist2)
                            seluruh_kiri.append(dist1)
                            anggota_clus2.append(kol_mandiri[j])
                            anggota2_kiribaru.append(kol_mandiri[j])
                            anggota2_kananbaru.append(kol_jumlah[j])

            if (len(hasil1)==len(hasil1_baru) and len(hasil2)==len(hasil2_baru)):
                plt.scatter(seluruh_kiri,seluruh_kanan,c='brown')
                plt.show()

                print ("Centroid pertama = ",cen_pertama1,"dan",cen_pertama2)
                print ("Centroid kedua = ",cen_kedua1,"dan",cen_kedua2)
                print ("----------------------------------------------------------------------------------------------------------------------------------------------")                
                print ("Data cluster pertama adalah :",anggota1_kiri,anggota1_kanan)
                print ("----------------------------------------------------------------------------------------------------------------------------------------------")
                print ("Data cluster kedua adalah :",anggota2_kiri,anggota2_kanan)
            else:
                program()

    mencari_centroid_dst()

program()
</code></pre>

<ol>
<li>Lalu klik Run &gt; Run Module dan hasilnya seperti dibawah ini. disini saya menggunakan 2 cluster yaitu menggunakan kolom pohon pelindung dan pohon produktif pada data penanaman pohon.</li>
</ol>
<p><img alt="1557588471101" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557588471101.png" /></p>
<ol>
<li>dibawah ini tampil bahwa centroid /cluster pertama berada pada data 198 dan 98 dan centroid kedua berada pada data 264 dan 65. </li>
</ol>
<p><img alt="1557588797613" src="C:\Users\roko\AppData\Roaming\Typora\typora-user-images\1557588797613.png" /></p>
<p><strong>Referensi :</strong></p>
<p><a href="https://informatikalogi.com/algoritma-k-means-clustering/">https://informatikalogi.com/algoritma-k-means-clustering/</a></p>
<p><a href="https://garudacyber.co.id/artikel/1514-kelebihan-dan-kekurangan-k-means-clustering">https://garudacyber.co.id/artikel/1514-kelebihan-dan-kekurangan-k-means-clustering</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 Ismi
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="http://struct.cc" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://ismihidayati.com/170441100014-decision-tree" class="md-footer-social__link fa fa-github-alt"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>