



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Menjelaskan tentang decision tree(pohon keputusan)">
      
      
        <link rel="canonical" href="https://ismihidayati.github.io/170441100014-decision-tree/">
      
      
        <meta name="author" content="Ismi Nur Hidayati.Z">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Materi Data Mining</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#decision-tree-pohon-keputusan" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://ismihidayati.github.io/170441100014-decision-tree" title="Materi Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Materi Data Mining
            </span>
            <span class="md-header-nav__topic">
              Materi
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://ismihidayati.com/170441100014-decision-tree" title="Go to repository" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    ismihidayati/170441100014-decision-tree
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="." title="Materi" class="md-tabs__link md-tabs__link--active">
        Materi
      </a>
    
  </li>

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://ismihidayati.github.io/170441100014-decision-tree" title="Materi Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Materi Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://ismihidayati.com/170441100014-decision-tree" title="Go to repository" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    ismihidayati/170441100014-decision-tree
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Materi
      </label>
    
    <a href="." title="Materi" class="md-nav__link md-nav__link--active">
      Materi
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#decision-tree-pohon-keputusan" title="DECISION TREE (POHON KEPUTUSAN)" class="md-nav__link">
    DECISION TREE (POHON KEPUTUSAN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#penerapan-decision-tree-pohon-keputusan" title="Penerapan decision tree (Pohon keputusan)" class="md-nav__link">
    Penerapan decision tree (Pohon keputusan)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#decision-tree-pohon-keputusan" title="DECISION TREE (POHON KEPUTUSAN)" class="md-nav__link">
    DECISION TREE (POHON KEPUTUSAN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#penerapan-decision-tree-pohon-keputusan" title="Penerapan decision tree (Pohon keputusan)" class="md-nav__link">
    Penerapan decision tree (Pohon keputusan)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Materi</h1>
                
                <h3 id="decision-tree-pohon-keputusan"><strong>DECISION TREE (POHON KEPUTUSAN)</strong><a class="headerlink" href="#decision-tree-pohon-keputusan" title="Permanent link">&para;</a></h3>
<hr />
<blockquote>
<p>Nama : ismi Nur Hidayati Z</p>
<p>Nim : 170441100014</p>
<p>Prodi : Sistem Informasi</p>
<p>Matakuliah : Data Mining (A)</p>
</blockquote>
<p><strong>latar belakang pohon keputusan</strong></p>
<p>​           Di dalam kehidupan manusia sehari-hari, manusia selalu dihadapkan oleh berbagai macam masalah dari berbagai macam bidang. Masalah-masalah ini yang dihadapi oleh
manusia tingkat kesulitan dan kompleksitasnya sangat bervariasi, mulai dari
yang teramat sederhana dengan sedikit faktor-faktor yang berkaitan dengan
masalah tersebut dan perlu diperhitungkan sampai dengan yang sangat rumit
dengan banyak sekali faktor-faktor turut serta berkaitan dengan masalah
tersebut dan perlu untuk diperhitungkan. </p>
<p>​               Untuk menghadapi masalah-masalah ini, manusia mulai mengembangkan sebuah sistem yang dapat membantu manusia agar dapat dengan mudah mampu untuk menyelesaikan masalah-masalah tersebut. Adapun pohon keputusan ini adalah sebuah jawaban akan sebuah sistem yang manusia kembangkan untuk membantu mencari dan membuat keputusan untuk masalah-masalah tersebut dan dengan memperhitungkan berbagai macam factor yang ada di dalam lingkup masalah tersebut. Dengan pohon keputusan, manusia dapat dengan mudah melihat mengidentifikasi dan melihat hubungan antara faktor-faktor yang mempengaruhi suatu masalah dan dapat mencari penyelesaian terbaik dengan memperhitungkan faktor-faktor tersebut. </p>
<p>​               Pohon keputusan ini juga dapat menganalisa nilai resiko dan nilai suatu informasi yang terdapat dalam suatu alternatif pemecahan masalah. Peranan pohon keputusan ini sebagai alat Bantu dalam mengambil keputusan (<em>decision support tool</em>) telah dikembangkan oleh manusia
sejak perkembangan teori pohon yang dilandaskan pada teori graf. Kegunaan pohon
keputusan yang sangat banyak ini membuatnya telah dimanfaatkan oleh manusia
dalam berbagai macam sistem pengambilan keputusan.</p>
<p><strong>Pengertian pohon keputusan</strong></p>
<p>​           Pohon yang dalam analisis pemecahan masalah pengambilan keputusan adalah pemetaan mengenai alternatif-alternatif pemecahan masalah yang dapat diambil dari masalah tersebut. Pohon tersebut juga memperlihatkan faktor-faktor kemungkinan/probablitas yang akan mempengaruhi alternatif-alternatif keputusan tersebut, disertai dengan estimasi hasil akhir yang akan didapat bila kita mengambil alternatif keputusan tersebut.</p>
<p><strong>Manfaat pohon keputusan</strong></p>
<p>​           Pohon keputusan adalah salah satu metode klasifikasi yang paling populer karena mudah untuk diinterpretasi oleh manusia. Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan. </p>
<p>​           Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-<em>break down</em> proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara eksplorasi data dan pemodelan, sehingga  sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Sering terjadi tawar menawar antara keakuratan model dengan transparansi model. Dalam beberapa aplikasi, akurasi dari sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan, misalnya sebuah perusahaan <em>direct mail</em> membuat sebuah model yang akurat untuk memprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja.</p>
<p><strong>Model pohon keputusan</strong></p>
<p>​           Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Contoh dari pohon keputusan dapat dilihat di Gambar berikut ini.</p>
<p><img alt="" src="assets/images/1.png" /></p>
<p>​           Disini setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan kelas data. Contoh di Gambar 1 adalah identifikasi pembeli komputer,dari pohon keputusan tersebut diketahui bahwa salah satu kelompok yang potensial membeli komputer adalah orang yang berusia di bawah 30 tahun dan juga pelajar. </p>
<p>​           Setelah sebuah pohon keputusan dibangun maka dapat digunakan untuk mengklasifikasikan <em>record</em> yang belum ada kelasnya. Dimulai dari <em>node root</em>,
menggunakan tes terhadap atribut dari <em>record</em> yang belum ada kelasnya tersebut lalu mengikuti cabang yang sesuai dengan hasil dari tes tersebut, yang akan membawa kepada <em>internal node</em> (<em>node</em> yang memiliki satu cabang masuk dan dua atau lebih cabang yang keluar), dengan cara harus melakukan tes lagi terhadap atribut atau <em>node</em> daun.</p>
<p>​            <em>Record</em> yang kelasnya tidak diketahui kemudian diberikan kelas yang sesuai dengan kelas yang ada pada <em>node</em> daun. Pada pohon keputusan setiap simpul daun menandai label kelas. Proses dalam pohon keputusan yaitu mengubah bentuk data (tabel) menjadi model pohon (<em>tree</em>) kemudian mengubah model pohon tersebut menjadi aturan (<em>rule</em>).</p>
<p><strong>Algoritma C4.5</strong></p>
<p>​           Salah satu algoritma induksi pohon keputusan yaitu ID3 (Iterative Dichotomiser 3).
ID3 dikembangkan oleh J. Ross Quinlan. Dalam prosedur algoritma ID3, input berupa sampel training, label training dan atribut. Algoritma C4.5 merupakan pengembangan dari ID3. Sedangkan pada perangkat lunak <em>open source</em> WEKA mempunyai versi sendiri C4.5 yang
dikenal sebagai J48.</p>
<p><img alt="" src="assets/images/2.png" /></p>
<p>​               Pohon dibangun dengan cara membagi data secara rekursif hingga tiap bagian terdiri dari data yang berasal dari kelas yang sama. Bentuk pemecahan (<em>split)</em> yang digunakan untuk membagi data tergantung dari jenis atribut yang digunakan dalam <em>split</em>. Algoritma C4.5 dapat menangani data numerik (kontinyu) dan diskret. <em>Split</em> untuk atribut numerik yaitu mengurutkan contoh berdasarkan atribut kontiyu A, kemudian membentuk minimum permulaan <em>(threshold</em>) M dari contoh-contoh yang ada dari kelas mayoritas pada setiap partisi yang bersebelahan, lalu menggabungkan partisi-partisi yang bersebelahan tersebut dengan kelas mayoritas yang sama. <em>Split</em> untuk atribut diskret <em>A</em> mempunyai bentuk <em>value (A)</em> ε <em>X</em> dimana <em>X</em> ⊂ <em>domain(A)</em>.</p>
<p>​               Jika suatu set data mempunyai beberapa pengamatan dengan <em>missing value</em> yaitu <em>record</em> dengan beberapa nilai variabel tidak ada, Jika jumlah pengamatan terbatas maka atribut dengan <em>missing value</em> dapat diganti dengan nilai rata-rata dari variabel yang bersangkutan.[Santosa,2007]</p>
<p>​               Untuk melakukan pemisahan obyek (<em>split)</em> dilakukan tes terhadap atribut dengan mengukur tingkat ketidakmurnian pada sebuah simpul (<em>node)</em>. Pada algoritma C.45 menggunakan rasio perolehan (<em>gain ratio</em>). Sebelum menghitung rasio perolehan, perlu menghitung dulu nilai informasi dalam satuan bits dari suatu kumpulan objek. Cara menghitungnya dilakukan dengan menggunakan konsep entropi.</p>
<p><img alt="" src="assets/images/3.png" /></p>
<p>​               S* adalah ruang (data) sampel yang digunakan untuk pelatihan, <em>p+</em> adalah jumlah yang bersolusi positif atau mendukung pada data sampel untuk kriteria tertentu dan <em>p-</em> adalah jumlah yang bersolusi negatif atau tidak mendukung pada data sampel untuk kriteria tertentu. ntropi(<em>S</em>) sama dengan 0, jika semua contoh pada S berada dalam kelas yang sama. Entropi(S) sama dengan 1, jika jumlah contoh positif dan negative dalam S adalah sama. Entropi(S) lebih dari 0 tetapi kurang dari 1, jika jumlah contoh positif dan negative dalam S tidak sama
[Mitchell,1997].Entropi split yang membagi <em>S</em> dengan <em>n</em> record menjadi himpunan-himpunan <em>S1</em> dengan <em>n1</em> baris dan <em>S2</em> dengan <em>n2</em> baris adalah :</p>
<p><img alt="" src="assets/images/4.png" /></p>
<p>​               Kemudian menghitung perolehan informasi dari output data atau variabel dependent <em>y</em> yang dikelompokkan berdasarkan atribut A, dinotasikan dengan <em>gain</em> (<em>y</em>,A). Perolehan informasi*, gain* (<em>y</em>,A), dari atribut A relative terhadap output data <em>y</em> adalah:</p>
<p><img alt="" src="assets/images/5.png" /></p>
<p>​               nilai (A) adalah semua nilai yang mungkin dari atribut A, dan <em>y*c adalah subset dari y dimana A mempunyai nilai c. Term pertama dalam persamaan diatas adalah *entropy</em> total <em>y</em> dan term kedua adalah entropy sesudah dilakukan pemisahan data berdasarkan atribut A.</p>
<p>Untuk menghitung rasio perolehan perlu diketahui suatu term baru yang disebut pemisahan informasi <em>(SplitInfo</em>). Pemisahan informasi dihitung dengan cara :</p>
<p><img alt="" src="assets/images/6.png" /></p>
<p>​               bahwa <em>S1</em> sampai <em>Sc</em> adalah <em>c</em> subset yang dihasilkan dari pemecahan <em>S</em> dengan menggunakan atribut A yang mempunyai sebanyak <em>c</em> nilai. Selanjutnya rasio perolehan (gain ratio) dihitung dengan cara :</p>
<p><img alt="" src="assets/images/7.png" /></p>
<p><strong>Kelebihan pohon keputusan</strong></p>
<ul>
<li>
<p>Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik.</p>
</li>
<li>
<p>Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu.</p>
</li>
<li>
<p>Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional</p>
</li>
<li>
<p>Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.</p>
</li>
</ul>
<p><strong>kekurangan pohon keputusan</strong></p>
<ul>
<li>
<p>Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</p>
</li>
<li>
<p>Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</p>
</li>
<li>
<p>Kesulitan dalam mendesain pohon keputusan yang optimal.</p>
</li>
<li>
<p>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</p>
</li>
</ul>
<h4 id="penerapan-decision-tree-pohon-keputusan"><strong>Penerapan decision tree (Pohon keputusan)</strong><a class="headerlink" href="#penerapan-decision-tree-pohon-keputusan" title="Permanent link">&para;</a></h4>
<hr />
<p><strong>Bahan yang digunakan</strong></p>
<ol>
<li>
<p>membuat data dalam bentuk csv . disini saya membuat data random forest.</p>
</li>
<li>
<p>install aplikasi python untuk menjalankan programnya.</p>
</li>
<li>
<p>install bebrapa library yang diperlukan. library yang diperlukan adalah numpy dan pandas.</p>
</li>
<li>
<p>install library ini pada command prompt. cara install library pandas adalah sebagai berikut :</p>
</li>
</ol>
<pre class="codehilite"><code class="language-python">pip install pandas</code></pre>

<ol>
<li>cara install library numpy adalah sebagai berikut :</li>
</ol>
<pre class="codehilite"><code class="language-python">pip install numpy</code></pre>

<ol>
<li>lalu masukan script berikut pada python :</li>
</ol>
<pre class="codehilite"><code class="language-python">from decision_tree import DecisionTree
import csv
import numpy as np  # http://www.numpy.org
import ast
import random

# Kode starter ini tidak berjalan. Anda harus menambahkan perubahan dan
# masukkan kode yang berjalan dengan benar.

"""
Disini,
1. X diasumsikan sebagai matriks dengan n baris dan kolom d di mana n adalah
jumlah total catatan dan d adalah jumlah fitur dari setiap catatan.
2. y diasumsikan sebagai vektor label dengan panjang n.
3. XX mirip dengan X, kecuali bahwa XX juga berisi label data untuk masing-masing
"""

"""

Kerangka ini disediakan untuk membantu Anda melaksanakan tugas. Anda harus
mengimplementasikan fungsi yang ada seperlunya. Anda dapat menambahkan fungsi baru
selama mereka dipanggil dari dalam kelas yang diberikan.

SANGAT PENTING!
JANGAN mengubah tanda tangan dari fungsi yang diberikan.
JANGAN mengubah bagian APART fungsi utama dari parameter forest_size.
"""

class RandomForest(object):
    num_trees = 0
    decision_trees = []

    # dataset bootstrap untuk pohon keputusan
    # bootstraps_datasets adalah daftar, di mana setiap daftar di bootstraps_datasets adalah dataset.stret bootstrap untuk pohon keputusan
    bootstraps_datasets = []

    #label kelas yang benar, sesuai dengan catatan dalam dataset bootstrap
    # bootstraps_labels adalah daftar, di mana daftar 'i'th berisi label yang sesuai dengan catatan
    # dataset 'i'th bootstrap.
    bootstraps_labels = []

    def __init__(self, num_trees):
        #Inisialisasi dilakukan di sini
        self.num_trees = num_trees
        self.decision_trees = [DecisionTree() for i in range(num_trees)]


    def _bootstrapping(self, XX, n):
        # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)
        #
        # TODO: Buat dataset sampel ukuran n dengan pengambilan sampel dengan penggantian
        #      dari dataset asli XX.
        # Perhatikan bahwa Anda juga perlu merekam label kelas yang sesuai
        # untuk catatan sampel untuk tujuan pelatihan.
        # n = len(XX)

        samples = [] # dataset sampel
        labels = []  # label kelas untuk catatan sampel
        for i in range(n):
            randomindex = random.randrange(0, n)
            samples.append(XX[randomindex][:-1])
            labels.append(XX[randomindex][-1])
        return (samples, labels)


    def bootstrapping(self, XX):
        # Menginisialisasi dataset bootstap untuk setiap pohon
        for i in range(self.num_trees):
            data_sample, data_label = self._bootstrapping(XX, len(XX))
            self.bootstraps_datasets.append(data_sample)
            self.bootstraps_labels.append(data_label)


    def fitting(self):
        # TODO: Latih pohon keputusan `num_trees` menggunakan set data bootstraps
        # dan label dengan memanggil fungsi belajar dari kelas DecisionTree Anda.
        for i in range(self.num_trees):
            self.decision_trees[i].learn(self.bootstraps_datasets[i], self.bootstraps_labels[i])

    def getIndexFromOriginal(self):
        return


    def voting(self, X):
        y = []

        for record in X:
            # Langkah-langkah berikut telah dilakukan di sini:
            #   1. Temukan kumpulan pohon yang menganggap catatan sebagai
            #      out-of-bag sample.
            #   2. Prediksi label menggunakan masing-masing pohon yang ditemukan di atas.
            #   3. Gunakan suara terbanyak untuk menemukan label final untuk catatan ini.
            votes = []
            for i in range(len(self.bootstraps_datasets)):
                dataset = self.bootstraps_datasets[i]
                if record not in dataset:
                    OOB_tree = self.decision_trees[i]
                    effective_vote = OOB_tree.classify(record)
                    votes.append(effective_vote)


            counts = np.bincount(votes)

            if len(counts) == 0:
                # TODO: Special case 
                #  Tangani wadah yang catatannya bukan sampel dari kantong
                # untuk salah satu pohon 
                y = self.bootstraps_labels[self.bootstraps_datasets.index(record)]
            else:
                y = np.append(y, np.argmax(counts))

        return y

# JANGAN mengubah fungsi utama selain dari parameter forest_size!
def main():
    X = list()
    y = list()
    XX = list()  # Berisi fitur data dan label data
    numerical_cols = set([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]) # indeks atribut numerik (kolom)

    # Memuat kumpulan data
    print 'reading hw4-data'
    with open("hw4-data.csv") as f:
        next(f, None)

        for line in csv.reader(f, delimiter=","):
            xline = []
            for i in range(len(line)):
                if i in numerical_cols:
                    # periksa apakah itu jenis aman untuk python
                    xline.append(ast.literal_eval(line[i]))
                else:
                    xline.append(line[i])

            X.append(xline[:-1])
            y.append(xline[-1])
            XX.append(xline[:])

    # TODO:Inisialisasi sesuai dengan implementasi Anda
    # SANGAT PENTING: Ukuran forest_size minimum harus 10
    forest_size = 20

    # Menginisialisasi  random forest.
    randomForest = RandomForest(forest_size)

    # Membuat set data bootstrap
    print 'creating the bootstrap datasets'
    randomForest.bootstrapping(XX)

    # Building trees in the forest
    print 'fitting the forest'
    randomForest.fitting()

    # Menghitung estimasi kesalahan yang tidak bisa dari random forest
    # berdasarkan estimasi kesalahan out-of-bag (OOB).
    y_predicted = randomForest.voting(X)

    # Membandingkan label yang diprediksi dan yang sebenarnya
    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]

    # ketepatan
    accuracy = float(results.count(True)) / float(len(results))

    print "accuracy: %.4f" % accuracy
    print "OOB estimate: %.4f" % (1-accuracy)


if __name__ == "__main__":
    main()
</code></pre>

<ol>
<li>dan jika di run hasilnya akan seperti ini :</li>
</ol>
<p><img alt="" src="assets/images/random forest.png" /></p>
<p><strong>Referensi Materi :</strong></p>
<p><a href="https://medium.com/iykra/mengenal-decision-tree-dan-manfaatnya-b98cf3cf6a8d">https://medium.com/iykra/mengenal-decision-tree-dan-manfaatnya-b98cf3cf6a8d</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 Ismi
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="assets/fonts/font-awesome.css">
    
      <a href="http://struct.cc" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://ismihidayati.com/170441100014-decision-tree" class="md-footer-social__link fa fa-github-alt"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"."}})</script>
      
    
  </body>
</html>